\chapter{Industrial Case Studies}
\label{ch:casestudies}

While Chapter~\ref{ch:landscape} provides a statistical overview, practitioners often ask for richer narratives describing how RL schedulers behave in realistic settings. This chapter consolidates six thematic case studies—job shops, flow shops, semiconductor fabs, energy-aware factories, regulated industries, and circular manufacturing—that synthesize both quantitative metrics and qualitative lessons.

\section{Flexible Job Shops and Aerospace Cells}
Flexible job shops serve as the proving ground for many RL advancements because they blend discrete dispatching with machine-selection flexibility. Studies such as \cite{RL-JSSP-2020,RL-GNN-2021} demonstrate that convolutional and graph encoders can outperform ATC and tabu search on Taillard instances, but industrial deployments introduce additional wrinkles: resource calendars, tooling compatibility, and human approvals. Aerospace-focused works \cite{RL-FLEX-DUAL-2024,RL-FLEX-2025} therefore augment the state space with fixture availability and takt-time windows, while curriculum learning scales policies from small benchmark instances to hundred-operation scenarios. Field interviews revealed that planners appreciate RL’s ability to adapt to rush orders without re-running entire MIP models; however, they demand dashboards that highlight which queue features triggered specific dispatching choices. Some teams address this by distilling policies into shallow decision trees for morning stand-ups, while retaining the full neural policy for execution.

Recurring design reviews also explore reward sensitivity. When reward weights drift too far toward tardiness penalties, the policy accelerates urgent jobs but neglects setup consolidation, causing fatigue on changeover crews. When weights prioritize energy savings, the policy defers low-priority jobs and risks violating customer service levels. To balance these forces, factories often establish ``reward councils'' where production, maintenance, and energy stakeholders negotiate targets each quarter. The resulting weights feed directly into retraining scripts, demonstrating how governance and modeling co-evolve.

\section{Flow Shops, Battery Lines, and Hybrid Plants}
Hybrid flow shops emphasize buffer coordination and stage-level synchronization. Cooperative MARL controllers \cite{RL-MARL-2021} improve throughput by letting each stage agent negotiate for shared buffers, whereas hierarchical actor-critic models \cite{RL-HFLOW-2021,Rao2024HybridMOHRL} separate strategic planning (manager level) from tactical machine assignments (worker level). Battery production lines bring digital twins into the loop: graph RL policies trained on FlexSim models \cite{RL-FLEXSIM-2024,RL-FLEXSIM-2025} retrain nightly using telemetry streamed from the manufacturing execution system. A notable lesson is the importance of “graceful degradation”—during twin outages, lines fall back to rule-based heuristics but continue logging state trajectories so the RL agent can retroactively learn from the blackout period. Flow-line engineers also emphasize changeover awareness: policies that ignore cleaning or setup durations inadvertently overload bottleneck stages. Consequently, the best-performing studies encode changeover matrices directly into the reward or action mask.

Buffer ownership policies often dictate success. Plants with consignment inventory or kanban loops require RL agents to respect contractual buffer limits, so multi-agent setups include ``inventory stewards'' that veto actions exceeding negotiated shares. Furthermore, flow-line teams increasingly pair RL with predictive maintenance: stage-level policies monitor vibration or thermal data and proactively reassign jobs to prevent imminent failures. These integrations reduce unplanned downtime but only work when maintenance and scheduling teams share telemetry pipelines.

\section{Semiconductor Manufacturing and Supply Chains}
Semiconductor fabs represent the most complex scheduling environment in the dataset. Double DQN strategies \cite{RL-SEMICON-2020} handle classical dispatching, but advanced nodes demand attention to EUV scanner availability, reticle cleaning, and energy tariffs. Graph RL approaches \cite{RL-SEMICON-2024,RL-SEMICON-2025} capture the re-entrant nature of wafer flows by embedding lot-tool relationships, while transfer-learning frameworks \cite{RL-SEMICON-TRANSFER-2023} cut training times when deploying to new fabs. Supply-chain studies extend the scope beyond single fabs: hierarchical RL coordinates wafer, test, and assembly schedules to smooth delivery commitments \cite{RL-SEMICON-CHAIN-2025,RL-SEMICON-SUPPLY-2025}. Two observations stand out. First, simulator fidelity is both a blessing and a curse; high-fidelity twins enable sophisticated policies but are rarely shareable, slowing academic replication. Second, energy-aware objectives—such as those in \cite{RL-SEMICON-MULTIOBJ-2024,RL-ENERGY-SEMICON-2022}—gain traction because utility costs now rival throughput penalties in many fabs. The case studies underscore the need for secure, explainable RL deployments that can interface with MES and yield-management systems without exposing proprietary recipes.

Security teams therefore insist on ``air-gapped inference'' where policies execute inside controlled environments and communicate with MES through hardened APIs. Some fabs even deploy inference on-premise accelerators to avoid transmitting sensitive queue states to the cloud. Another emerging theme is wafer genealogy: RL decisions must respect lot histories, recipe qualifications, and reticle allocation constraints. Embedding these data models into state representations required close collaboration between process engineers and data architects—a reminder that RL deployments hinge as much on information modeling as on algorithms.

\section{Energy-Aware and Microgrid-Integrated Factories}
Sustainability mandates are reshaping manufacturing KPIs. Early dueling-DQN prototypes \cite{RL-ENERGY-2021} treated energy tariffs as scalar penalties, whereas contemporary works integrate carbon prices, energy-storage levels, and equipment degradation signals \cite{RL-MARL-ENERGY-2022,RL-MICROGRID-2024,RL-ENERGY-2025}. Multi-agent SAC architectures proved particularly effective: one agent schedules production, another manages microgrid resources, and a coordinator reconciles conflicting objectives such as carbon caps versus delivery promises \cite{RL-MICROGRID-2025,RL-MICROGRID-2025B}. Interviews with energy managers revealed that RL schedulers allowed them to participate in demand-response markets without manual replanning, but only after robust fail-safes were implemented (e.g., caps on how frequently machines can be throttled). These case studies make it clear that RL must integrate seamlessly with energy-management systems and provide audit logs for every load-shedding action to satisfy regulators.

To institutionalize these capabilities, organizations often codify ``carbon playbooks'' linking RL reward parameters to corporate sustainability targets. When carbon prices rise, the playbook prescribes new reward weights and outlines validation tests to ensure throughput remains acceptable. Additionally, energy-aware deployments frequently integrate predictive weather services to anticipate renewable output; the RL agent then schedules energy-intensive jobs during sunny or windy periods. This coupling between external forecasts and internal scheduling exemplifies the broader shift toward cyber-physical coordination.

\section{Regulated Industries: Pharma, Biopharma, and Remanufacturing}
Pharmaceutical and biopharma plants deal with stringent validation requirements. Actor-critic methods for batching \cite{RL-BATCH-2021,RL-BATCH-2024} penalize partial fills and enforce cleaning intervals, while mode-switching controllers manage hybrid batch/continuous lines \cite{RL-BATCH-CONT-2025}. Distributional RL helps quantify risk by modeling KPI uncertainty directly \cite{RL-BIOPHARMA-2024}. Remanufacturing studies \cite{RL-MANUF-2025,RL-MANUF-2030} introduce material-return variability and circular-economy objectives, showing that RL can orchestrate disassembly, inspection, and reassembly under uncertain yields. Practitioners in these sectors emphasize documentation: every RL decision must be traceable for auditors. Consequently, experiments often pair RL with digital notebooks that capture state snapshots, actions, and rationale tags—a pattern worth emulating in other domains.

Validation teams also demand scenario stress tests. Before releasing new policies, pharma plants replay historical deviations (equipment faults, quality alarms) to confirm the RL scheduler behaves conservatively. Remanufacturing facilities simulate surges in return volumes or quality downgrades to ensure policies still honor contractual service levels. The emphasis on ``explainable resilience''—showing not only that metrics improve, but also that guardrails hold under stress—distinguishes regulated industries from other domains.

\section{Circular Manufacturing and Long-Horizon Planning}
Emerging work explores RL for circular manufacturing networks where products cycle between production, use, remanufacturing, and recycling \cite{RL-MANUF-2030}. These scenarios extend scheduling horizons to months or years, necessitating hierarchical policies that connect plant-level dispatching with network-level capacity planning. Although evidence remains preliminary, the case studies highlight promising directions: multi-objective rewards balancing throughput with recycling rates, meta-learning for rapid adaptation when return rates spike, and cooperative agents that negotiate resource sharing across plants. Integrating these insights with the energy and microgrid advances summarized earlier could unlock end-to-end sustainable manufacturing strategies.

\section{Cross-Domain Lessons}
Across all domains, three cross-cutting lessons emerge. First, RL excels when paired with accurate disruption models—machine failures, rush orders, tariff swings. Policies trained on overly sanitized scenarios fail when reality deviates. Second, digital twins are most valuable when they exchange data bidirectionally; RL policies supply action plans back into the twin, which then updates sensors and returns richer state observations. Third, human interpretability remains non-negotiable. Whether in aerospace, pharma, or energy, operators expect explanations when the policy deviates from habitual practice. Embedding explainability artifacts (saliency plots, decision tree surrogates, annotated timelines) directly into MES dashboards closes this gap and accelerates trust.
