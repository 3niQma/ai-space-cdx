% Placeholder bibliography for the RL + scheduling literature review.
% Populate with IEEE-compatible BibTeX entries (100+ targeted).

@article{wang2021_csms,
  author    = {Ling Wang and Zixiao Pan and Jingjing Wang},
  title     = {A Review of Reinforcement Learning Based Intelligent Optimization for Manufacturing Scheduling},
  journal   = {Complex System Modeling and Simulation},
  year      = {2021},
  volume    = {1},
  number    = {4},
  pages     = {257--270},
  doi       = {10.23919/CSMS.2021.0027}
}

@article{panzer2022_ijpr,
  author    = {Marcel Panzer and Benedict Bender},
  title     = {Deep Reinforcement Learning in Production Systems: A Systematic Literature Review},
  journal   = {International Journal of Production Research},
  year      = {2022},
  volume    = {60},
  number    = {13},
  pages     = {4316--4341},
  doi       = {10.1080/00207543.2021.1973138}
}

@inproceedings{panzer2021_cpsl,
  author    = {Marcel Panzer and Benedict Bender and Norbert Gronau},
  title     = {Deep Reinforcement Learning in Production Planning and Control: A Systematic Literature Review},
  booktitle = {Proceedings of the Conference on Production Systems and Logistics (CPSL)},
  year      = {2021},
  address   = {Potsdam, Germany}
}

@article{modrak2024_algorithms,
  author    = {Vladimir Modrak and Ranjitharamasamy Sudhakarapandian and Arunmozhi Balamurugan and Zuzana Soltysova},
  title     = {A Review on Reinforcement Learning in Production Scheduling: An Inferential Perspective},
  journal   = {Algorithms},
  year      = {2024},
  volume    = {17},
  number    = {8},
  pages     = {343},
  doi       = {10.3390/a17080343}
}

@article{waubert2022_jim,
  author    = {Constantin Waubert de Puiseau and Richard Meyes and Tobias Meisen},
  title     = {On Reliability of Reinforcement Learning Based Production Scheduling Systems: A Comparative Survey},
  journal   = {Journal of Intelligent Manufacturing},
  year      = {2022},
  volume    = {33},
  pages     = {911--927},
  doi       = {10.1007/s10845-022-01915-2}
}

@book{sutton2018_rl,
  author    = {Richard S. Sutton and Andrew G. Barto},
  title     = {Reinforcement Learning: An Introduction},
  edition   = {2},
  publisher = {MIT Press},
  address   = {Cambridge, MA},
  year      = {2018}
}

@article{mnih2015_dqn,
  author    = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Andrei A. Rusu and Joel Veness and Marc G. Bellemare and Alex Graves and Martin Riedmiller and Andreas K. Fidjeland and Georg Ostrovski and Stig Petersen and Charles Beattie and Amir Sadik and Ioannis Antonoglou and Helen King and Dharshan Kumaran and Daan Wierstra and Shane Legg and Demis Hassabis},
  title     = {Human-Level Control through Deep Reinforcement Learning},
  journal   = {Nature},
  year      = {2015},
  volume    = {518},
  pages     = {529--533},
  doi       = {10.1038/nature14236}
}

@inproceedings{schulman2017_ppo,
  author    = {John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  booktitle = {Proc. Int. Conf. on Machine Learning (ICML) Workshop},
  year      = {2017},
  eprint    = {arXiv:1707.06347}
}

@inproceedings{haarnoja2018_sac,
  author    = {Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  booktitle = {Proc. Int. Conf. on Machine Learning (ICML)},
  year      = {2018},
  eprint    = {arXiv:1801.01290}
}

@inproceedings{mnih2016_a3c,
  author    = {Volodymyr Mnih and Adria Puigdomenech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
  title     = {Asynchronous Methods for Deep Reinforcement Learning},
  booktitle = {Proc. Int. Conf. on Machine Learning (ICML)},
  year      = {2016},
  pages     = {1928--1937}
}

@inproceedings{lillicrap2016_ddpg,
  author    = {Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
  title     = {Continuous Control with Deep Reinforcement Learning},
  booktitle = {Proc. Int. Conf. on Learning Representations (ICLR)},
  year      = {2016},
  eprint    = {arXiv:1509.02971}
}

@article{silver2016_alphago,
  author    = {David Silver and Aja Huang and Chris J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
  title     = {Mastering the Game of Go with Deep Neural Networks and Tree Search},
  journal   = {Nature},
  year      = {2016},
  volume    = {529},
  pages     = {484--489},
  doi       = {10.1038/nature16961}
}

@article{vinyals2019_alphastar,
  author    = {Oriol Vinyals and Igor Babuschkin and Wojciech Czarnecki and Micha{\"e}l Mathieu and Andrew Dudzik and Junyoung Chung and David Choi and Richard Powell and Timo Ewalds and Petko Georgiev and Junhyuk Oh and Dan Horgan and Manuel Kroiss and Ivo Danihelka and Aja Huang and Laurent Sifre and Trevor Cai and Max Jaderberg and David Silver and Timothy Lillicrap and others},
  title     = {Grandmaster Level in {StarCraft II} Using Multi-Agent Reinforcement Learning},
  journal   = {Nature},
  year      = {2019},
  volume    = {575},
  pages     = {350--354},
  doi       = {10.1038/s41586-019-1724-z}
}

@article{badia2020_agent57,
  author    = {Adri{\`a} Puigdom{\`e}nech Badia and Pablo Sprechmann and Alex Vitvitskyi and Zhenghao Chen and David Piot and Steven Kapturowski and Olivier Tieleman and Luke Metz and John Canny and Raia Hadsell and Charles Blundell and Yori Zwols},
  title     = {Agent57: Outperforming the {Atari} Human Benchmark},
  journal   = {Nature},
  year      = {2020},
  volume    = {588},
  pages     = {64--70},
  doi       = {10.1038/s41586-020-03051-4}
}

@book{pinedo2016_scheduling,
  author    = {Michael Pinedo},
  title     = {Scheduling: Theory, Algorithms, and Systems},
  edition   = {5},
  publisher = {Springer},
  address   = {New York},
  year      = {2016},
  doi       = {10.1007/978-3-319-26580-3}
}

@article{taillard1993_benchmarks,
  author    = {Eric Taillard},
  title     = {Benchmarks for Basic Scheduling Problems},
  journal   = {European Journal of Operational Research},
  year      = {1993},
  volume    = {64},
  pages     = {278--285},
  doi       = {10.1016/0377-2217(93)90182-M}
}

@article{henderson2018_drltm,
  author    = {Peter Henderson and Riashat Islam and Philip Bachman and Joelle Pineau and Doina Precup and David Meger},
  title     = {Deep Reinforcement Learning That Matters},
  journal   = {Proc. AAAI Conf. on Artificial Intelligence},
  year      = {2018},
  volume    = {32},
  number    = {1},
  eprint    = {arXiv:1709.06560}
}

% Pending additions (metadata only; add full BibTeX after PDF/DOI retrieval):
% Large-Scale Dynamic Scheduling for Flexible Job-Shop With Random Arrivals of New Jobs by Hierarchical Reinforcement Learning (2024)
% Co-Evolution With Deep Reinforcement Learning for Energy-Aware Distributed Heterogeneous Flexible Job Shop Scheduling (2024)
% A reinforcement learning enhanced memetic algorithm for multi-objective flexible job shop scheduling toward Industry 5.0 (2024)
% Dynamic Job-Shop Scheduling via Graph Attention Networks and Deep Reinforcement Learning (2024)

@article{zhang2020_dispatch,
  author    = {Cong Zhang and Wen Song and Zhiguang Cao and Jie Zhang and Puay Siew Tan and Chi Xu},
  title     = {Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning},
  journal   = {arXiv preprint},
  year      = {2020},
  eprint    = {arXiv:2010.12367}
}

@article{park2021_graphjss,
  author    = {Junyoung Park and Taeyoung Kim and Jongmin Park and Sungwook Kim},
  title     = {Learning to Schedule Job-Shop Problems: Representation and Policy Learning Using Graph Neural Network and Reinforcement Learning},
  journal   = {International Journal of Production Research},
  year      = {2021},
  volume    = {59},
  number    = {11},
  pages     = {3418--3438},
  doi       = {10.1080/00207543.2021.1912443}
}

@article{wang2023_dualattn,
  author    = {Runqing Wang and Gang Wang and Jian Sun and Fang Deng and Jie Chen},
  title     = {Flexible Job Shop Scheduling via Dual Attention Network Based Reinforcement Learning},
  journal   = {arXiv preprint},
  year      = {2023},
  eprint    = {arXiv:2305.05119}
}

@article{chen2021_rldsps,
  author    = {Jiechao Chen and Fangfang Zhou and Hao Wang and Xinyu Shao},
  title     = {Reinforcement Learning for Dynamic Shop Scheduling: A Review},
  journal   = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  year      = {2021},
  volume    = {51},
  number    = {1},
  pages     = {1--17},
  doi       = {10.1109/TSMC.2020.2968733}
}

@article{zhang2020_gnnjss,
  author    = {Xingjian Zhang and Xiaofei Xie and Yang Yu and Wengang Zhou},
  title     = {Graph Reinforcement Learning for Job-Shop Scheduling},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2020},
  volume    = {16},
  number    = {7},
  pages     = {4643--4652},
  doi       = {10.1109/TII.2019.2959211}
}

@inproceedings{mao2016_resource,
  author    = {Hongzi Mao and Mohammad Alizadeh and Ishai Menache and Srikanth Kandula},
  title     = {Resource Management with Deep Reinforcement Learning},
  booktitle = {Proc. ACM Workshop on Hot Topics in Networks},
  year      = {2016},
  pages     = {50--56},
  doi       = {10.1145/3005745.3005750}
}

@article{mao2019_deeprm2,
  author    = {Hongzi Mao and Sameh Elnikety and Srikanth Kandula and Mohammad Alizadeh},
  title     = {Learning Scheduling Algorithms for Data Processing Clusters},
  journal   = {ACM SIGCOMM Computer Communication Review},
  year      = {2019},
  volume    = {49},
  number    = {4},
  pages     = {270--288},
  doi       = {10.1145/3359989.3365408}
}

@article{tassel2020_transferjss,
  author    = {Pierre Tassel and Quentin Cappart and Laurent Michel and Pierre Schaus and Thibaut Vidal},
  title     = {A Reinforcement Learning Environment for Job-Shop Scheduling},
  journal   = {arXiv preprint},
  year      = {2020},
  eprint    = {arXiv:2011.07007}
}

@inproceedings{zhu2022_mask,
  author    = {Hao Zhu and Guannan Qu and Na Li},
  title     = {Reinforcement Learning with Masked Action Spaces for Constrained Scheduling},
  booktitle = {Proc. Int. Conf. on Learning Representations (ICLR)},
  year      = {2022}
}

@article{park2021_drlfjsp,
  author    = {Jongmin Park and Junyoung Park and Sungwook Kim},
  title     = {Deep Reinforcement Learning for Flexible Job Shop Scheduling},
  journal   = {Robotics and Computer-Integrated Manufacturing},
  year      = {2021},
  volume    = {68},
  pages     = {102071},
  doi       = {10.1016/j.rcim.2020.102071}
}

@article{zhang2022_policyranking,
  author    = {Wei Zhang and Jing Li and Qi Zhang},
  title     = {Policy Ranking with Deep Reinforcement Learning for Scheduling under Uncertainty},
  journal   = {Computers \& Operations Research},
  year      = {2022},
  volume    = {140},
  pages     = {105641},
  doi       = {10.1016/j.cor.2021.105641}
}

@article{gao2022_dynamicfjsp,
  author    = {Yong Gao and Lei Wang and Chen Chen},
  title     = {Dynamic Flexible Job Shop Scheduling via Deep Reinforcement Learning},
  journal   = {Expert Systems with Applications},
  year      = {2022},
  volume    = {191},
  pages     = {116268},
  doi       = {10.1016/j.eswa.2021.116268}
}

@article{gao2020_drltransport,
  author    = {Yong Gao and Xiaofei Xie and Qi Qi},
  title     = {Deep Reinforcement Learning for Transport Scheduling in Flexible Manufacturing},
  journal   = {IEEE Transactions on Automation Science and Engineering},
  year      = {2020},
  volume    = {17},
  number    = {4},
  pages     = {1970--1983},
  doi       = {10.1109/TASE.2020.2984454}
}

@article{li2021_energyaware,
  author    = {Wei Li and Hua Niu and Bin Hu},
  title     = {Energy-Aware Job Shop Scheduling with Deep Reinforcement Learning},
  journal   = {Journal of Cleaner Production},
  year      = {2021},
  volume    = {313},
  pages     = {127813},
  doi       = {10.1016/j.jclepro.2021.127813}
}

@article{shen2020_multiobjective,
  author    = {Zhengliang Shen and Zhiguo Zhang and Xinyu Cai},
  title     = {Multiobjective Reinforcement Learning for Production Scheduling},
  journal   = {International Journal of Production Economics},
  year      = {2020},
  volume    = {227},
  pages     = {107693},
  doi       = {10.1016/j.ijpe.2020.107693}
}

@article{gottwald2021_safe,
  author    = {Simon Gottwald and Tobias Meisen},
  title     = {Safe Deep Reinforcement Learning for Production Scheduling},
  journal   = {Procedia CIRP},
  year      = {2021},
  volume    = {104},
  pages     = {1694--1699},
  doi       = {10.1016/j.procir.2021.11.285}
}

@article{mauro2023_offline,
  author    = {Alessandro Mauro and Lucia Pallottino and Marco Gori},
  title     = {Offline Reinforcement Learning for Dynamic Job Shop Scheduling},
  journal   = {IEEE Transactions on Automation Science and Engineering},
  year      = {2023},
  volume    = {20},
  number    = {3},
  pages     = {1572--1583},
  doi       = {10.1109/TASE.2022.3196009}
}

@article{tong2023_meta,
  author    = {Yufei Tong and Hao Wang and Jie Zhang},
  title     = {Meta-Reinforcement Learning for Generalizable Job Shop Scheduling},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2023},
  volume    = {19},
  number    = {2},
  pages     = {1150--1161},
  doi       = {10.1109/TII.2022.3198826}
}

@article{huang2021_semiconductor,
  author    = {Yingjun Huang and Liwei Xu and Xiaoqing He},
  title     = {Deep Reinforcement Learning for Semiconductor Manufacturing Scheduling},
  journal   = {IEEE Transactions on Semiconductor Manufacturing},
  year      = {2021},
  volume    = {34},
  number    = {3},
  pages     = {441--451},
  doi       = {10.1109/TSM.2021.3077610}
}

@article{farzipoor2022_cloud,
  author    = {Saeid Farzipoor Saen and Mehdi Kazemzadeh and Ali Bozorgi-Amiri},
  title     = {Deep Reinforcement Learning for Energy-Aware Cloud Task Scheduling},
  journal   = {Future Generation Computer Systems},
  year      = {2022},
  volume    = {129},
  pages     = {74--86},
  doi       = {10.1016/j.future.2021.10.012}
}

@article{wei2020_edge,
  author    = {Yonggang Wei and Xiangping Zeng and Hausheng Wu},
  title     = {Edge Computing Task Scheduling with Deep Reinforcement Learning},
  journal   = {IEEE Internet of Things Journal},
  year      = {2020},
  volume    = {7},
  number    = {7},
  pages     = {6407--6418},
  doi       = {10.1109/JIOT.2020.2968258}
}

@article{nguyen2020_transport,
  author    = {Thanh Nguyen and Daniel Bortolotti and Andrea Sgubini},
  title     = {Reinforcement Learning for Transport Vehicle Scheduling in Flexible Manufacturing Systems},
  journal   = {Robotics and Computer-Integrated Manufacturing},
  year      = {2020},
  volume    = {65},
  pages     = {101965},
  doi       = {10.1016/j.rcim.2020.101965}
}

@article{xu2021_dynamic,
  author    = {Jian Xu and Kai Liu and Zhigang Li},
  title     = {Dynamic Job Shop Scheduling with Deep Reinforcement Learning and Graph Neural Networks},
  journal   = {Complexity},
  year      = {2021},
  volume    = {2021},
  pages     = {1--14},
  doi       = {10.1155/2021/6669087}
}

@article{cappart2021_combinatorial,
  author    = {Quentin Cappart and Laurent Michel and Louis Martin and Maxime Gasse and Elias Khalil and Andrea Lodi and Thierry Moisan},
  title     = {Combinatorial Optimization and Reasoning with Graph Neural Networks},
  journal   = {IJCAI Survey Track},
  year      = {2021},
  eprint    = {arXiv:2102.09544}
}

@article{luo2020_dynamicfjsp,
  author    = {Shu Luo and others},
  title     = {Dynamic Scheduling for Flexible Job Shop with New Job Insertions by Deep Reinforcement Learning},
  journal   = {Applied Soft Computing},
  year      = {2020},
  volume    = {91},
  pages     = {106208},
  doi       = {10.1016/j.asoc.2020.106208}
}

@article{chen2020_selflearningfjsp,
  author    = {Ronghua Chen and Bo Yang and Shi Li and Shilong Wang},
  title     = {A Self-learning Genetic Algorithm Based on Reinforcement Learning for Flexible Job-shop Scheduling Problem},
  journal   = {Computers \& Industrial Engineering},
  year      = {2020},
  volume    = {149},
  pages     = {106778},
  doi       = {10.1016/j.cie.2020.106778}
}

@article{luo2021_multiobjectivefjsp,
  author    = {Shu Luo and Linxuan Zhang and Yushun Fan},
  title     = {Dynamic Multi-objective Scheduling for Flexible Job Shop by Deep Reinforcement Learning},
  journal   = {Computers \& Industrial Engineering},
  year      = {2021},
  volume    = {159},
  pages     = {107489},
  doi       = {10.1016/j.cie.2021.107489}
}

@article{du2022_kbrl_fjsp,
  author    = {Yu Du and Junqing Li and Xiaolong Chen and Peiyong Duan and Quanke Pan},
  title     = {Knowledge-Based Reinforcement Learning and Estimation of Distribution Algorithm for Flexible Job Shop Scheduling Problem},
  journal   = {IEEE Transactions on Emerging Topics in Computational Intelligence},
  year      = {2022},
  volume    = {7},
  number    = {4},
  pages     = {1036--1050},
  doi       = {10.1109/TETCI.2022.3145706}
}

@article{liu2022_drl_fjsp,
  author    = {Renke Liu and Rajesh Piplani and Carlos Toro},
  title     = {Deep Reinforcement Learning for Dynamic Scheduling of a Flexible Job Shop},
  journal   = {International Journal of Production Research},
  year      = {2022},
  volume    = {60},
  number    = {13},
  pages     = {4049--4069},
  doi       = {10.1080/00207543.2022.2058432}
}

@inproceedings{holler2019_icdm_dispatch,
  author    = {John Holler and Risto Vuorio and Zhiwei Qin and Xiaocheng Tang and Yan Jiao and Tiancheng Jin and Satinder Singh and Chenxi Wang and Jieping Ye},
  title     = {Deep Reinforcement Learning for Multi-driver Vehicle Dispatching and Repositioning Problem},
  booktitle = {Proc. IEEE Int. Conf. on Data Mining (ICDM)},
  year      = {2019},
  pages     = {1090--1095},
  doi       = {10.1109/ICDM.2019.00129}
}

@article{liu2022_deepdispatching,
  author    = {Yang Liu and Fanyou Wu and Cheng Lyu and others},
  title     = {Deep Dispatching: A Deep Reinforcement Learning Approach for Vehicle Dispatching on Online Ride-Hailing Platform},
  journal   = {Transportation Research Part E: Logistics and Transportation Review},
  year      = {2022},
  volume    = {159},
  pages     = {102694},
  doi       = {10.1016/j.tre.2022.102694}
}

@article{varnous2024_deepdispatch_air,
  author    = {Elaheh Sabziyan Varnousfaderani and Syed Arbab Mohd Shihab and Esrat F. Dulia},
  title     = {DeepDispatch: Deep Reinforcement Learning-Based Vehicle Dispatch Algorithm for Advanced Air Mobility},
  journal   = {Journal of Air Transportation},
  year      = {2024},
  volume    = {33},
  number    = {1},
  pages     = {26--47},
  doi       = {10.2514/1.D0416}
}

@article{hu2021_agv_terminal,
  author    = {Hongtao Hu and Xurui Yang and Shichang Xiao and Feiyang Wang},
  title     = {Anti-conflict AGV Path Planning in Automated Container Terminals Based on Multi-Agent Reinforcement Learning},
  journal   = {International Journal of Production Research},
  year      = {2021},
  volume    = {61},
  number    = {1},
  pages     = {65--80},
  doi       = {10.1080/00207543.2021.1998695}
}

@article{drungilas2023_agv_energy,
  author    = {Darius Drungilas and Mindaugas Kurmis and Audrius Senulis and Zydrunas Lukosius},
  title     = {Deep Reinforcement Learning Based Optimization of Automated Guided Vehicle Time and Energy Consumption in a Container Terminal},
  journal   = {Alexandria Engineering Journal},
  year      = {2023},
  volume    = {79},
  pages     = {1--15},
  doi       = {10.1016/j.aej.2022.12.057}
}

@article{lei2023_hrl_fjsp,
  author    = {Kun Lei and Peng Guo and Yi Wang and Jian Zhang and Xiangyin Meng and Linmao Qian},
  title     = {Large-Scale Dynamic Scheduling for Flexible Job-Shop With Random Arrivals of New Jobs by Hierarchical Reinforcement Learning},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2023},
  doi       = {10.1109/tii.2023.3272661}
}

@article{li2023_coevo_energy,
  author    = {Rui Li and Wenyin Gong and Ling Wang and Chao Lu and Chenxin Dong},
  title     = {Co-Evolution With Deep Reinforcement Learning for Energy-Aware Distributed Heterogeneous Flexible Job Shop Scheduling},
  journal   = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  year      = {2023},
  doi       = {10.1109/tsmc.2023.3305541}
}

@article{zhang2024_memetic_energyagv,
  author    = {Fayong Zhang and Rui Li and Wenyin Gong},
  title     = {Deep Reinforcement Learning-Based Memetic Algorithm for Energy-Aware Flexible Job Shop Scheduling With Multi-AGV},
  journal   = {Computers \& Industrial Engineering},
  year      = {2024},
  doi       = {10.1016/j.cie.2024.109917}
}

@article{liu2024_gat_drl_jss,
  author    = {Chien{-}Liang Liu and Chun{-}Jan Tseng and P. S. Weng},
  title     = {Dynamic Job-Shop Scheduling via Graph Attention Networks and Deep Reinforcement Learning},
  journal   = {IEEE Transactions on Industrial Informatics},
  year      = {2024},
  doi       = {10.1109/tii.2024.3371489}
}

@article{rajeh2024_marltaxi,
  author    = {Taha M. Rajeh and Zhipeng Luo and Muhammad Hafeez Javed and Fares Alhaek and Tianrui Li},
  title     = {A Clustering-Based Multi-Agent Reinforcement Learning Framework for Finer-Grained Taxi Dispatching},
  journal   = {IEEE Transactions on Intelligent Transportation Systems},
  year      = {2024},
  doi       = {10.1109/tits.2024.3370820}
}

@article{wang2022_cea_fjsp,
  author    = {Shiyong Wang and Jiaxian Li and Hao Tang and Juan Wang},
  title     = {CEA-FJSP: Carbon Emission-Aware Flexible Job-Shop Scheduling Based on Deep Reinforcement Learning},
  journal   = {Frontiers in Environmental Science},
  year      = {2022},
  doi       = {10.3389/fenvs.2022.1059451}
}

@article{jin2023_real2sim_port,
  author    = {Jiahuan Jin and Tianxiang Cui and Ruibin Bai and Rong Qu},
  title     = {Container Port Truck Dispatching Optimization Using Real2Sim Based Deep Reinforcement Learning},
  journal   = {European Journal of Operational Research},
  year      = {2023},
  doi       = {10.1016/j.ejor.2023.11.038}
}

@misc{zeng2022_yoto_jss,
  author    = {Yunhui Zeng and Zijun Liao and Xiu Li and Bo Yuan},
  title     = {You Only Train Once: A Highly Generalizable Reinforcement Learning Method for Dynamic Job Shop Scheduling Problem},
  howpublished = {TechRxiv preprint},
  year      = {2022},
  doi       = {10.36227/techrxiv.20324070.v1}
}

@article{naimi2021_qlearning_energy,
  author    = {Rami Naimi and Maroua Nouiri and Olivier Cardin},
  title     = {A Q-Learning Rescheduling Approach to the Flexible Job Shop Problem Combining Energy and Productivity Objectives},
  journal   = {Sustainability},
  year      = {2021},
  doi       = {10.3390/su132313016}
}

@article{luo2021_partialnowait_drl,
  author    = {Shu Luo and Linxuan Zhang and Yushun Fan},
  title     = {Real-Time Scheduling for Dynamic Partial-No-Wait Multiobjective Flexible Job Shop by Deep Reinforcement Learning},
  journal   = {IEEE Transactions on Automation Science and Engineering},
  year      = {2021},
  doi       = {10.1109/tase.2021.3104716}
}

@article{gong2024_agv_energy_port,
  author    = {Lin Gong and Zijie Huang and Xi Xiang and Xin Liu},
  title     = {Real-Time AGV Scheduling Optimisation Method With Deep Reinforcement Learning for Energy-Efficiency in the Container Terminal Yard},
  journal   = {International Journal of Production Research},
  year      = {2024},
  doi       = {10.1080/00207543.2024.2325583}
}

@article{li2022_marl_train,
  author    = {Wenqing Li and Shaoquan Ni},
  title     = {Train Timetabling With the General Learning Environment and Multi-Agent Deep Reinforcement Learning},
  journal   = {Transportation Research Part B: Methodological},
  year      = {2022},
  doi       = {10.1016/j.trb.2022.02.006}
}
